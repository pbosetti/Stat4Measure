---
title:
  Statistica per la Misura
  
  Parte 7. --- Design of Experiments
runningheader: "Design of Experiments" # only for pdf output
subtitle: "Design of Experiments" # only for html output
author:
  Paolo Bosetti,
  Dipartimento di Ingegneria Industriale, Università di Trento 
date: "Ultimo aggiornamento: `r Sys.Date()`"
output:
  tufte::tufte_handout:
    number_sections: yes
    toc: yes
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_html:
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
bibliography: skeleton.bib
link-citations: yes
header-includes:
  - \usepackage[italian]{babel}
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \fancyhead[LO,LE]{\rightmark}
  - \fancyfoot[LO,LE]{Statistica per la Misura}
  - \fancyfoot[CO,CE]{\includegraphics[height=0.5cm]{by-nc-sa.png}}
  - \fancyfoot[RO,RE]{\url{paolo.bosetti@unitn.it}}
---

```{r setup, include=FALSE}
library(tufte)
library(latex2exp)
library(tidyverse)
library(tidymodels)
library(magrittr)
library(grDevices)
source("myfunctions.R")
knitr::opts_chunk$set(tidy=F)
theme_set(theme_gray()+theme(legend.position = "bottom"))
```
```{=tex}
\newcommand{\boxedpar}[1]{\bigskip\noindent\fbox{\parbox{\textwidth}{{#1}}}\bigskip}
```


# Perché progettare gli esperimenti?
`r newthought("Un esperimento è un'attività")` volta a raccogliere dati che consentano:

1. di confermare un'ipotesi teorica;
2. di calibrare i parametri di un modello.
3. di identificare i fattori che influiscono su un processo;

Nel primo caso siamo interessati soprattutto a verificare la **forma** del modello teorico di un processo/fenomeno; nel secondo caso, la forma del modello è nota e si desidera identificarne i **parametri**; nel terzo caso il modello stesso può essere ignoto, e si è interessati soprattutto a conoscere i **fattori** (cioè le variabili indipendenti) che governano il processo/fenomeno.

Il **secondo caso** è affrontato mediante regressione di un modello statistico (lineare o lineare generalizzato). Nel **primo caso** alla regressione si affianca lo studio degli intervalli di confidenza (parametrici o via bootstrap), che mi consentono di valutare quanto il modello sia adatto a rappresentare la realtà. In entrambi questi casi la dimensionalità del problema è tipicamente contenuta: si tratta di problemi univariati o al più bivariati.

Il **terzo caso**, invece, mira a costruire un modello approssimato, tipicamente al primo grado, della risposta di un sistema o processo al variare di un numero di fattori indipendenti relativamente elevato (dieci o più). Questo modello può essere poi la base per lo studio di dettaglio e lo sviluppo di modelli più raffinati per un sottoinsieme di fattori, ricadendo nel primo e nel terzo caso.

Consideriamo ora il caso di un fenomeno univariato: il **numero minimo di livelli** dell'unico fattore che devono essere indagati per costruire o validare un modello sono ovviamente pari a $k=d+1$, dove $d$ è il grado del modello: se il modello è quadratico ($d=2$) ho bisogno di valutare la risposta del processo in almeno 3 differenti livelli. Se voglio essere anche in grado di valutare la varianza ho bisogno di più livelli oppure **di ripetere l'esperimento più volte** ad ogni livello.
```{marginfigure}
**Nota**: c'è una sostanziale differenza tra **ripetere l'esperimento** e **ripetere la misurazione**: nel primo caso è l'intero esperimento che va ripetuto, fino alla misurazione finale; nel secondo caso si ripete soltanto la misurazione. 

Il secondo fornisce solo informazioni sulla varianza del sistema di misura, mentre se volgiamo valutare la varianza complessiva del processo dobbiamo ripetere l'intera operazione di valutazione del processo per un particolare livello dei parametri indipendenti (fattori).
```

Ma se il processo/fenomeno è multivariato e il numero di fattori $n$ è elevato, il numero di **trattamenti** (cioè combinazioni di livelli di fattori) che devo effettuare cresce esponenzialmente con il numero di fattori, cioè $k^n$.

\boxedpar{
Siccome ogni singolo esperimento è associato ad un valore economico (un costo), ciò significa che il costo di un esperimento cresce esponenzialmente con il numero di fattori.

Di qui deriva la necessità di progettare un esperimento---soprattutto quelli del secondo tipo sopra descritto---in modo da minimizzarne il costo e massimizzarne l'efficacia.
}

Quest'ultimo è tipicamente il caso degli **esperimenti industriali**, in cui si ha un processo produttivo complesso e multi-fisico, per il quale non è disponibile---o è molto difficile da realizzare---un modello analitico/numerico. In questi casi si ha la necessità di individuare quali fattori hanno influenza sulla resa del processo e di definire almeno un modello del primo grado che consenta di definire in che direzione è necessario cambiare un parametro per migliorare la resa.

Dato che le tecniche statistiche necessarie per affrontare esperimenti del primo e del secondo tipo sono già state affrontate nelle Parti precedenti (regressione e bootstrap, soprattutto), nel resto di questa Parte ci occuperemo di esperimenti del terzo tipo. Si noti, tuttavia, che **la dicitura "terzo tipo" non è consolidata, ma è solo utilizzata**, per chiarezza di esposizione, **in questo documento**.

# Piani fattoriali completi
`r newthought("Un esperimento del terzo tipo")` è chiamato **piano fattoriale**, dato che pianifica una combinazione di fattori per indagare la loro influenza sulla resa di un processo.
```{marginfigure}
**Nota**: la locuzione Inglese originaria è *factorial plan*, e non *factorial plane*.
```

In quest'ambito, il **processo** è visto come una **scatola nera**: un sistema opaco che non ci consente di vedere il funzionamento interno, ma che accetta una serie di $n$ **ingressi** (i fattori) soggetti a variabilità statistica e fornisce un'unica **risposta** in uscita. 

L'obiettivo del piano fattoriale è definire la correlazione tra ingressi e uscita (tra fattori e resa). L'obiettivo del **Design of Experiments** (*DoE*) è definire le combinazioni di trattamenti in modo da massimizzare l'efficienza dell'esperimento (intesa come rapporto tra informazioni ottenute e numero di trattamenti investigati).

Introduciamo il concetto di piano fattoriale a partire da un esempio elementare: abbiamo due fattori, $A$ e $B$, ciascuno con due livelli, che chiameremo $A^+$, $A^-$, $B^+$ e $B^-$. Supponiamo che la combinazione $(A^-,B^-)$ sia la normale configurazione operativa del processo.

```{r include=FALSE}
data <- tribble (
  ~A, ~B, ~resa, ~Yates,
  "A-", "B-", 20, "$(1)$",
  "A+", "B-", 50, "$a$",
  "A-", "B+", 30, "$b$",
  "A+", "B+", 12, "$ab$"
)
```
Se vogliamo investigare la risposta del processo ad una variazione dei due fattori, l'approccio più semplice è cambiare il valore di ogni fattore, **uno alla volta**, come illustrato in Fig. \ref{fig:onebyone}, supponendo di valutare la resa come riportato nella seguente tabella:
```{r onebyone, fig.margin=T, echo=F, fig.cap="Esperimento modificando un fattore alla volta"}
ggplot(data[1:3,], aes(x=A, y=B)) +
  geom_label(aes(x=A, y=B, label=resa))
```
```{r echo=F}
data[1:3,] %>% knitr::kable()
```

Da queste informazioni possiamo calcolarci l'**effetto** di $A$ e di $B$. Introduciamo anzitutto la **notazione di Yates** per riferirsi ai **trattamenti**: ogni trattamento è indicato con la le lettere minuscole dei relativi fattori se a livello alto, nulla se a livello basso, e si utilizza $(1)$ se tutti i fattori sono a livello basso.
Gli effetti (che si indicano col nome del loro fattore) risultano quindi:
\begin{eqnarray}
A &=& a - (1) = `r data$resa[2]` - `r data$resa[1]` = `r data$resa[2]-data$resa[1]`\\
B &=& b - (1) = `r data$resa[3]` - `r data$resa[1]` = `r data$resa[3]-data$resa[1]`
\end{eqnarray}
Cioè entrambi i fattori hanno un effetto positivo e l'effetto di $A$ è maggiore di quello di $B$.

Tuttavia questo approccio ha due limiti:

1. non posso dire se c'è interazione tra $A$ e $B$, se cioè l'effetto di $A$ dipende dal **livello* di $B$, e viceversa;
2. a meno di non replicare l'esperimento più volte, non ho nessuna indicazione statistica sull'effetto, perché non posso stimare la varianza.

Supponiamo ora di completare l'esperimento con un trattamento in cui **entrambi i fattori sono a livello alto**, cioè il trattamento $ab$: otteniamo la tabella seguente e la Fig. \ref{fig:2to2}:
```{r echo=F}
data %>% knitr::kable()
```
```{r 2to2, fig.margin=T, echo=F, fig.cap="Esperimento fattoriale completo"}
ggplot(data, aes(x=A, y=B)) +
  geom_label(aes(x=A, y=B, label=resa))
A <- with(data, (resa[2]+resa[4])/2 - (resa[1]+resa[3])/2)
B <- with(data, (resa[3]+resa[4])/2 - (resa[1]+resa[2])/2)
AB <- with(data, (resa[1]+resa[4])/2 - (resa[2]+resa[3])/2)
```

Abbiamo realizzato un **piano fattoriale completo** di tipo $2^2$, cioè con due fattori, ciascuno a 2 livelli e un totale di $2^2=4$ trattamenti.

Per la stima degli effetti questo piano fattoriale ci consente di fare un passo in avanti:
\begin{eqnarray}
A &=& \frac{a+ab}{2} - \frac{(1) + b}{2} = `r A`\\
B &=& \frac{b+ab}{2} - \frac{(1) + a}{2} = `r B` \\
AB &=& \frac{a+b}{2} - \frac{(1)+ab}{2} = `r AB`
\end{eqnarray}
cioè l'effetto di $A$ è positivo, ma l'effetto di $B$ risulta **in media negativo** dato che tra di due fattori c'è un'interazione non nulla $AB=`r AB`$. In altre parole, come si evince anche dalla Fig. \ref{fig:2to2}, aumentare $A$ ha un effetto positivo quanto $B$ è basso, ma **negativo** quando $B$ è alto.

```{r interaction1, echo = F, fig.margin=T, fig.cap="Grafico di interazione tra i due fattori $A$ e $B$"}
ggplot(data, aes(x=A, y=resa, color=B, group=B)) + 
  geom_line(size=2) + 
  geom_point(size=4)
```
Questa situazione è ben rappresentabile con un **grafico di interazione** come in Fig. \ref{fig:interaction1}: il fatto che le due rette **non siano parallele** significa che c'è interazione tra i due fattori. Viceversa, se esse fossero parallele significherebbe che l'effetto di ciascun fattore è indipendente dall'altro.
```{r interaction2, echo = F, fig.margin=T, fig.cap="Grafico di interazione tra i due fattori $A$ e $B$"}
ggplot(data, aes(x=B, y=resa, color=A, group=A)) + 
  geom_line(size=2) + 
  geom_point(size=4)
```

Dal confronto tra Fig. \ref{fig:interaction1} e Fig. \ref{fig:interaction2} si capisce come sia indifferente quale dei due fattori sia in traccia e quale sull'ascissa: la conclusione è sempre la stessa: rette parallele significa nessuna interazione, e viceversa.

Si è detto che il secondo punto debole dell'esperimento di Fig. \ref{fig:onebyone} è che non consente la stima della varianza, a meno di non ripetere gli esperimento (che però aumenta il costo). Si vedrà nel resto di questa Parte che il piano fattoriale di Fig. \ref{fig:2to2}, invece, consente anche una stima della varianza.
```{marginfigure}
**Nota**: stimare la varianza è essenziale, perché se essa risulta maggiore dell'effetto è chiaro che nessuno degli effetti calcolati ha più valore di un numero casuale.
```



## Piani fattoriali $k^2$

## Piani fattoriali $2^n$

# Estensioni e frazionamenti
`r newthought("")`

## Central Composite Design

## Piani fattoriali non replicati

## Piani fattoriali frazionati

